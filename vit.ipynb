{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "import torch\n",
    "import datasets\n",
    "import numpy as np\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import v2\n",
    "from datasets import load_dataset\n",
    "\n",
    "#datasets.config.DOWNLOADED_DATASETS_PATH='./datasets'\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 128\n",
    "num_layers = 8\n",
    "batch_size = 64\n",
    "\n",
    "dropout = 0.0\n",
    "max_lr = 1e-3\n",
    "wd = 0.05\n",
    "path = './'\n",
    "epoches = config.num_epoches\n",
    "warmup_steps = 2000\n",
    "\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    #v2.PILToTensor(),\n",
    "    v2.RandomResizedCrop(64, scale=(0.7, 1)),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    #v2.RandomRotation(60),\n",
    "    #v2.ToDtype(torch.float32, scale=True),\n",
    "    #v2.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]),\n",
    "    # v2.Normalize(mean=[0.478], std=[0.268]),\n",
    "    # v2.RandomErasing(),\n",
    "    # v2.RandAugment(),\n",
    "])\n",
    "\n",
    "eval_transforms = v2.Compose([\n",
    "    v2.PILToTensor(),\n",
    "    #v2.ToDtype(torch.float32, scale=True),\n",
    "    #v2.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]),\n",
    "\n",
    "])\n",
    "\n",
    "cutmix = v2.CutMix(num_classes=config.num_classes)\n",
    "mixup = v2.MixUp(num_classes=config.num_classes)\n",
    "cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "from Dataset import CustomImageDataSet, load_data\n",
    "\n",
    "train_x, train_y, val_x, val_y = load_data(config)\n",
    "train_dataset, val_dataset = CustomImageDataSet(train_x, transform=transforms), CustomImageDataSet(val_x, transform=transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "import torchvision\n",
    "from models.Vit import ViT\n",
    "#model = torchvision.models.VisionTransformer(image_size=64, num_classes=200, patch_size=16, num_layers=8, num_heads=8, hidden_dim=512, mlp_dim=1024).cuda()\n",
    "model = ViT(image_size=64, num_classes=200, patch_size=16, num_layers=8, num_heads=8, hidden_dim=512, mlp_dim=1024).cuda()\n",
    "#model = torchvision.models.vit_b_16(image_size=64, num_classes=200,).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of param: 34225291\n",
      "number of iters: 1535\n",
      "Epoch 0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: \n",
      "Epoch 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss: \n",
      "Epoch 2: \n",
      "Average train loss: \n",
      "Epoch 3: \n",
      "Average train loss: \n",
      "Epoch 4: \n",
      "Average train loss: \n",
      "Epoch 5: \n",
      "Average train loss: \n",
      "Epoch 6: \n",
      "Average train loss: \n",
      "Epoch 7: \n",
      "Average train loss: \n",
      "Epoch 8: \n",
      "Average train loss: \n",
      "Epoch 9: \n",
      "Average train loss: \n",
      "Epoch 10: \n",
      "Average train loss: \n",
      "Epoch 11: \n",
      "Average train loss: \n",
      "Epoch 12: \n",
      "Average train loss: \n",
      "Epoch 13: \n",
      "Average train loss: \n",
      "Epoch 14: \n",
      "Average train loss: \n",
      "Epoch 15: \n",
      "Average train loss: \n",
      "Epoch 16: \n",
      "Average train loss: \n",
      "Epoch 17: \n",
      "Average train loss: \n",
      "Epoch 18: \n",
      "Average train loss: \n",
      "Epoch 19: \n",
      "Average train loss: \n",
      "Epoch 20: \n",
      "Average train loss: \n",
      "Epoch 21: \n",
      "Average train loss: \n",
      "Epoch 22: \n",
      "Average train loss: \n",
      "Epoch 23: \n",
      "Average train loss: \n",
      "Epoch 24: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(output, label, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     45\u001b[0m batch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m---> 46\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[0;32m     48\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1e1\u001b[39m)\n",
      "File \u001b[1;32md:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pre-train the model with proxy-task of simple reconstruction\n",
    "# dataset\n",
    "train_dataset, val_dataset = CustomImageDataSet(train_x, transform=transforms), CustomImageDataSet(val_x, transform=transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "valid_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, pin_memory=True, num_workers=4)\n",
    "total_train_steps = len(train_x) * epoches\n",
    "\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f'number of param: {num_params}')\n",
    "print(f'number of iters: {len(train_dataloader)}')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd, betas=(0.9, 0.98))\n",
    "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_steps)\n",
    "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, total_train_steps-warmup_steps, eta_min=max_lr*0.01)\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, [scheduler1, scheduler2], [warmup_steps])\n",
    "\n",
    "test_name = f\"{config.dataset}_vit_{config.num_epoches}_reconstruction\"\n",
    "# test_name = 'cnn_4_stage'\n",
    "writer = SummaryWriter(path+'/runs/'+test_name, max_queue=120)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "train_step = 0\n",
    "best_loss = float('inf')\n",
    "for epoch in range(epoches):\n",
    "\n",
    "    losses = []\n",
    "    model.train()\n",
    "    print(\"Epoch {}: \".format(epoch))\n",
    "    #print(\"Loading data...\")\n",
    "    for img, label in train_dataloader:\n",
    "        #print(\"Finished loading data.\")\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        batch_loss = 0\n",
    "        model.train()\n",
    "        # for mini_data in data.chunk(num_mini_batches, 0):\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            output = model.reconstruct(img)\n",
    "            loss = F.mse_loss(output, label) \n",
    "\n",
    "        batch_loss += loss.item()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1e1)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        writer.add_scalar('Loss/train', batch_loss, train_step)\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "        train_step += 1\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    print(\"Average train loss: \".format(avg_loss))\n",
    "    writer.add_scalar('Loss/train_average', avg_loss, epoch)\n",
    "\n",
    "    #losses.clear()\n",
    "    #model.eval()\n",
    "    \"\"\" for img, label in valid_dataloader:\n",
    "\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        with torch.inference_mode(), torch.autocast(device_type=\"cuda\"):\n",
    "            \n",
    "            output = model.reconstruct(img)  \n",
    "            #final_target = torch.reshape(label, (-1,))\n",
    "            loss = F.mse_loss(output, label, reduction='none')\n",
    "\n",
    "            pred_labels = output.argmax(1)\n",
    "            acc = (pred_labels==label).float().mean()\n",
    "\n",
    "\n",
    "        losses.append(loss.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    avg_loss = np.mean(np.concatenate(losses, 0)).item()\n",
    "    writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "    losses.clear() \n",
    "    \n",
    "    if avg_loss <= best_loss:\n",
    "        print(avg_loss)\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), path+'/runs/'+test_name+'/best_model.pt')\n",
    "    \"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test\n",
    "import matplotlib.pyplot as plt\n",
    "#optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd)\n",
    "for img, label in val_dataloader:\n",
    "    label = label.cuda()\n",
    "    im = img.cuda()\n",
    "    output = model.reconstruct(im)\n",
    "    #loss = F.mse_loss(output, label)\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    #optimizer.zero_grad()\n",
    "    \n",
    "    output = output[0].permute(1,2,0).detach().cpu().numpy()#.astype(np.int32)\n",
    "    im = im[0].detach().cpu().permute(1,2,0).numpy()#.astype(np.int32)\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    plt.imshow(output)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "#model_scripted.save('model_scripted.pt')\n",
    "torch.save(model.state_dict(), 'pre_trained/vit/2.pt')\n",
    "pt_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for prediction\n",
    "train_dataset, val_dataset = CustomImageDataSet(train_x, train_y, transform=transforms), CustomImageDataSet(val_x, val_y, transform=None)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, pin_memory=True, num_workers=4)\n",
    "\n",
    "total_train_steps = len(train_x) * epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new untrained model\n",
    "model = ViT(image_size=64, num_classes=200, patch_size=16, num_layers=8, num_heads=8, hidden_dim=512, mlp_dim=1024).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of param: 34225291\n",
      "number of iters: 1535\n",
      "\n",
      " Epoch 0 train loss: 3.669653058440367\n",
      "\n",
      " Epoch 0 validation acc: 0.189346581697464\n",
      "3.6560778617858887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 train loss: 3.576504865609085\n",
      "\n",
      " Epoch 1 validation acc: 0.18561282753944397\n",
      "\n",
      " Epoch 2 train loss: 3.356809682100526\n",
      "\n",
      " Epoch 2 validation acc: 0.23025567829608917\n",
      "3.4523398876190186\n",
      "\n",
      " Epoch 3 train loss: 3.1878697629860246\n",
      "\n",
      " Epoch 3 validation acc: 0.24249188601970673\n",
      "3.3781208992004395\n",
      "\n",
      " Epoch 4 train loss: 3.043333322761113\n",
      "\n",
      " Epoch 4 validation acc: 0.2884334325790405\n",
      "3.11153507232666\n",
      "\n",
      " Epoch 5 train loss: 2.9210758557148786\n",
      "\n",
      " Epoch 5 validation acc: 0.2957589328289032\n",
      "3.050579071044922\n",
      "\n",
      " Epoch 6 train loss: 2.81034253024123\n",
      "\n",
      " Epoch 6 validation acc: 0.2761566638946533\n",
      "\n",
      " Epoch 7 train loss: 2.7128639639006376\n",
      "\n",
      " Epoch 7 validation acc: 0.28735795617103577\n",
      "\n",
      " Epoch 8 train loss: 2.6123662417020395\n",
      "\n",
      " Epoch 8 validation acc: 0.3105519413948059\n",
      "3.0224199295043945\n",
      "\n",
      " Epoch 9 train loss: 2.520581093983852\n",
      "\n",
      " Epoch 9 validation acc: 0.317552775144577\n",
      "3.0059564113616943\n",
      "\n",
      " Epoch 10 train loss: 2.4321369975708205\n",
      "\n",
      " Epoch 10 validation acc: 0.34502843022346497\n",
      "2.888636589050293\n",
      "\n",
      " Epoch 11 train loss: 2.350918329189189\n",
      "\n",
      " Epoch 11 validation acc: 0.3284902572631836\n",
      "\n",
      " Epoch 12 train loss: 2.267312760306492\n",
      "\n",
      " Epoch 12 validation acc: 0.3309862017631531\n",
      "\n",
      " Epoch 13 train loss: 2.1904065288627574\n",
      "\n",
      " Epoch 13 validation acc: 0.3467532694339752\n",
      "\n",
      " Epoch 14 train loss: 2.109338342328025\n",
      "\n",
      " Epoch 14 validation acc: 0.3391842544078827\n",
      "\n",
      " Epoch 15 train loss: 2.0288321867051264\n",
      "\n",
      " Epoch 15 validation acc: 0.3311282694339752\n",
      "\n",
      " Epoch 16 train loss: 1.9548817965805725\n",
      "\n",
      " Epoch 16 validation acc: 0.3465503454208374\n",
      "\n",
      " Epoch 17 train loss: 1.8893317884265017\n",
      "\n",
      " Epoch 17 validation acc: 0.347869336605072\n",
      "\n",
      " Epoch 18 train loss: 1.8166595857384151\n",
      "\n",
      " Epoch 18 validation acc: 0.3442167341709137\n",
      "\n",
      " Epoch 19 train loss: 1.7495549259046002\n",
      "\n",
      " Epoch 19 validation acc: 0.34407466650009155\n",
      "\n",
      " Epoch 20 train loss: 1.6959832316112828\n",
      "\n",
      " Epoch 20 validation acc: 0.3415990173816681\n",
      "\n",
      " Epoch 21 train loss: 1.6327905070898199\n",
      "\n",
      " Epoch 21 validation acc: 0.3410511314868927\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f'number of param: {num_params}')\n",
    "print(f'number of iters: {len(train_dataloader)}')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd, betas=(0.9, 0.98))\n",
    "\n",
    "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_steps)\n",
    "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, total_train_steps-warmup_steps, eta_min=max_lr*0.01)\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, [scheduler1, scheduler2], [warmup_steps])\n",
    "\n",
    "# %%\n",
    "import math\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "test_name = f\"{config.dataset}_vit_{config.num_epoches}_direction_{config.ssm_direction}\"\n",
    "# test_name = 'cnn_4_stage'\n",
    "writer = SummaryWriter(path+'/runs/'+test_name, max_queue=120)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "train_step = 0\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in range(epoches):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    #indices = torch.randperm(train_x.shape[0])\n",
    "    for img, label in train_dataloader:\n",
    "        #img, label = train_x[indices[i:i+batch_size]], train_y[indices[i:i+batch_size]]\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        #img, label = cutmix_or_mixup(img, label)\n",
    "        batch_loss = 0\n",
    "        model.train()\n",
    "        # for mini_data in data.chunk(num_mini_batches, 0):\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            output = model(img)\n",
    "            final_output = torch.reshape(output, (-1, output.shape[-1]))\n",
    "            loss = F.cross_entropy(final_output, label) \n",
    "\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1e2)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    " \n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        writer.add_scalar('Loss/train', batch_loss, train_step)\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "        train_step += 1\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    print(f'\\n Epoch {epoch} train loss: {avg_loss}')\n",
    "    writer.add_scalar('Loss/train_average', avg_loss, epoch)\n",
    "\n",
    "\n",
    "    \n",
    "    losses.clear()\n",
    "    accs = []\n",
    "    model.eval()\n",
    "    for img, label in val_dataloader:\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        with torch.inference_mode(), torch.autocast(device_type=\"cuda\"):\n",
    "            \n",
    "            output = model(img)\n",
    "            final_target = torch.reshape(label, (-1,))\n",
    "            loss = F.cross_entropy(output, final_target, reduction='none')\n",
    "            \n",
    "            pred_labels = output.argmax(1)\n",
    "            acc = (pred_labels==label).float().mean()\n",
    "            accs.append(acc)\n",
    "\n",
    "\n",
    "        losses.append(loss.cpu().numpy())\n",
    "    \n",
    "    avg_loss = np.mean(np.concatenate(losses, 0)).item()\n",
    "    avg_acc= sum(accs) / len(accs)\n",
    "    print(f'\\n Epoch {epoch} validation acc: {avg_acc}')\n",
    "\n",
    "    writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "\n",
    "    writer.add_scalar('Acc/valid', avg_acc, epoch)\n",
    "\n",
    "\n",
    "    losses.clear()\n",
    "\n",
    "    if avg_loss <= best_loss:\n",
    "        print(avg_loss)\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), path+'/runs/'+test_name+'/best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from_scratch = model\n",
    "model = pt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of param: 34225291\n",
      "number of iters: 6137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "d:\\xie\\Vision\\ViT\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 0 train loss: 5.180237956829484\n",
      "\n",
      " Epoch 0 validation acc: 0.04603658616542816\n",
      "4.7902045249938965\n",
      "\n",
      " Epoch 1 train loss: 4.606016997271608\n",
      "\n",
      " Epoch 1 validation acc: 0.07205284386873245\n",
      "4.511613845825195\n",
      "\n",
      " Epoch 2 train loss: 4.431593119797031\n",
      "\n",
      " Epoch 2 validation acc: 0.09878048300743103\n",
      "4.324558734893799\n",
      "\n",
      " Epoch 3 train loss: 4.314900493590747\n",
      "\n",
      " Epoch 3 validation acc: 0.11615853756666183\n",
      "4.232433795928955\n",
      "\n",
      " Epoch 4 train loss: 4.222218315473534\n",
      "\n",
      " Epoch 4 validation acc: 0.12154471129179001\n",
      "4.1840949058532715\n",
      "\n",
      " Epoch 5 train loss: 4.146213893492563\n",
      "\n",
      " Epoch 5 validation acc: 0.1336382031440735\n",
      "4.084181308746338\n",
      "\n",
      " Epoch 6 train loss: 4.093706667724331\n",
      "\n",
      " Epoch 6 validation acc: 0.13932926952838898\n",
      "4.07025671005249\n",
      "\n",
      " Epoch 7 train loss: 4.0525148680219045\n",
      "\n",
      " Epoch 7 validation acc: 0.13810975849628448\n",
      "4.0505452156066895\n",
      "\n",
      " Epoch 8 train loss: 4.008689122730694\n",
      "\n",
      " Epoch 8 validation acc: 0.14786584675312042\n",
      "4.019979000091553\n",
      "\n",
      " Epoch 9 train loss: 3.9841619826924903\n",
      "\n",
      " Epoch 9 validation acc: 0.15518292784690857\n",
      "3.9556872844696045\n",
      "\n",
      " Epoch 10 train loss: 3.9477828077720627\n",
      "\n",
      " Epoch 10 validation acc: 0.15071137249469757\n",
      "3.9508938789367676\n",
      "\n",
      " Epoch 11 train loss: 3.9150338242452967\n",
      "\n",
      " Epoch 11 validation acc: 0.14207316935062408\n",
      "\n",
      " Epoch 12 train loss: 3.892933506365026\n",
      "\n",
      " Epoch 12 validation acc: 0.16402438282966614\n",
      "3.8831946849823\n",
      "\n",
      " Epoch 13 train loss: 3.8718439931684583\n",
      "\n",
      " Epoch 13 validation acc: 0.16249999403953552\n",
      "3.8758161067962646\n",
      "\n",
      " Epoch 14 train loss: 3.8536613905528907\n",
      "\n",
      " Epoch 14 validation acc: 0.16331300139427185\n",
      "\n",
      " Epoch 15 train loss: 3.832797257815158\n",
      "\n",
      " Epoch 15 validation acc: 0.16798779368400574\n",
      "\n",
      " Epoch 16 train loss: 3.8201513668409635\n",
      "\n",
      " Epoch 16 validation acc: 0.17398373782634735\n",
      "3.8284969329833984\n",
      "\n",
      " Epoch 17 train loss: 3.802404469070012\n",
      "\n",
      " Epoch 17 validation acc: 0.17398373782634735\n",
      "3.8185207843780518\n",
      "\n",
      " Epoch 18 train loss: 3.7889527373230765\n",
      "\n",
      " Epoch 18 validation acc: 0.178048774600029\n",
      "3.7984237670898438\n",
      "\n",
      " Epoch 19 train loss: 3.773237380449986\n",
      "\n",
      " Epoch 19 validation acc: 0.1733739823102951\n",
      "\n",
      " Epoch 20 train loss: 3.76490874863106\n",
      "\n",
      " Epoch 20 validation acc: 0.17835365235805511\n",
      "3.7674720287323\n",
      "\n",
      " Epoch 21 train loss: 3.7512132208141806\n",
      "\n",
      " Epoch 21 validation acc: 0.17642275989055634\n",
      "\n",
      " Epoch 22 train loss: 3.7454567522378706\n",
      "\n",
      " Epoch 22 validation acc: 0.17591463029384613\n",
      "\n",
      " Epoch 23 train loss: 3.734007191265641\n",
      "\n",
      " Epoch 23 validation acc: 0.16808941960334778\n",
      "\n",
      " Epoch 24 train loss: 3.7223795421430026\n",
      "\n",
      " Epoch 24 validation acc: 0.18719512224197388\n",
      "3.7282137870788574\n",
      "\n",
      " Epoch 25 train loss: 3.7109006817146217\n",
      "\n",
      " Epoch 25 validation acc: 0.17845527827739716\n",
      "\n",
      " Epoch 26 train loss: 3.7067765708620004\n",
      "\n",
      " Epoch 26 validation acc: 0.178048774600029\n",
      "\n",
      " Epoch 27 train loss: 3.698166603507486\n",
      "\n",
      " Epoch 27 validation acc: 0.19237804412841797\n",
      "3.7222330570220947\n",
      "\n",
      " Epoch 28 train loss: 3.694190943806378\n",
      "\n",
      " Epoch 28 validation acc: 0.18963414430618286\n",
      "\n",
      " Epoch 29 train loss: 3.6872320634758937\n",
      "\n",
      " Epoch 29 validation acc: 0.1845528483390808\n",
      "\n",
      " Epoch 30 train loss: 3.6766921972362114\n",
      "\n",
      " Epoch 30 validation acc: 0.18668699264526367\n",
      "\n",
      " Epoch 31 train loss: 3.6662477479611155\n",
      "\n",
      " Epoch 31 validation acc: 0.1944105625152588\n",
      "3.7168684005737305\n",
      "\n",
      " Epoch 32 train loss: 3.6633215766009783\n",
      "\n",
      " Epoch 32 validation acc: 0.1837398260831833\n",
      "\n",
      " Epoch 33 train loss: 3.6544540739222615\n",
      "\n",
      " Epoch 33 validation acc: 0.19186991453170776\n",
      "3.705612897872925\n",
      "\n",
      " Epoch 34 train loss: 3.647920229661459\n",
      "\n",
      " Epoch 34 validation acc: 0.18658536672592163\n",
      "\n",
      " Epoch 35 train loss: 3.644623170016312\n",
      "\n",
      " Epoch 35 validation acc: 0.1942073106765747\n",
      "3.6944456100463867\n",
      "\n",
      " Epoch 36 train loss: 3.6394789807859027\n",
      "\n",
      " Epoch 36 validation acc: 0.19308942556381226\n",
      "3.6803338527679443\n",
      "\n",
      " Epoch 37 train loss: 3.628202073442367\n",
      "\n",
      " Epoch 37 validation acc: 0.19969511032104492\n",
      "3.641061305999756\n",
      "\n",
      " Epoch 38 train loss: 3.621148559855622\n",
      "\n",
      " Epoch 38 validation acc: 0.18892276287078857\n",
      "\n",
      " Epoch 39 train loss: 3.622530745589735\n",
      "\n",
      " Epoch 39 validation acc: 0.1914634108543396\n",
      "\n",
      " Epoch 40 train loss: 3.623208167596848\n",
      "\n",
      " Epoch 40 validation acc: 0.1931910514831543\n",
      "\n",
      " Epoch 41 train loss: 3.609799600024361\n",
      "\n",
      " Epoch 41 validation acc: 0.1961382031440735\n",
      "\n",
      " Epoch 42 train loss: 3.5994649078318792\n",
      "\n",
      " Epoch 42 validation acc: 0.20254065096378326\n",
      "\n",
      " Epoch 43 train loss: 3.5990471122356933\n",
      "\n",
      " Epoch 43 validation acc: 0.19796746969223022\n",
      "\n",
      " Epoch 44 train loss: 3.5936589591837635\n",
      "\n",
      " Epoch 44 validation acc: 0.19959348440170288\n",
      "\n",
      " Epoch 45 train loss: 3.592135371419065\n",
      "\n",
      " Epoch 45 validation acc: 0.2011178880929947\n",
      "\n",
      " Epoch 46 train loss: 3.5866725650695357\n",
      "\n",
      " Epoch 46 validation acc: 0.18993902206420898\n",
      "\n",
      " Epoch 47 train loss: 3.5772419825854276\n",
      "\n",
      " Epoch 47 validation acc: 0.1947154402732849\n",
      "\n",
      " Epoch 48 train loss: 3.5770934807257757\n",
      "\n",
      " Epoch 48 validation acc: 0.19512194395065308\n",
      "\n",
      " Epoch 49 train loss: 3.5766649010788645\n",
      "\n",
      " Epoch 49 validation acc: 0.20894308388233185\n",
      "3.6144838333129883\n",
      "\n",
      " Epoch 50 train loss: 3.5677084413086804\n",
      "\n",
      " Epoch 50 validation acc: 0.21117885410785675\n",
      "3.5674643516540527\n",
      "\n",
      " Epoch 51 train loss: 3.5611000961175043\n",
      "\n",
      " Epoch 51 validation acc: 0.20294715464115143\n",
      "\n",
      " Epoch 52 train loss: 3.5619712192149393\n",
      "\n",
      " Epoch 52 validation acc: 0.20182926952838898\n",
      "\n",
      " Epoch 53 train loss: 3.55774249819954\n",
      "\n",
      " Epoch 53 validation acc: 0.19878047704696655\n",
      "\n",
      " Epoch 54 train loss: 3.5572711969987565\n",
      "\n",
      " Epoch 54 validation acc: 0.20528455078601837\n",
      "\n",
      " Epoch 55 train loss: 3.5554420302352048\n",
      "\n",
      " Epoch 55 validation acc: 0.20416666567325592\n",
      "\n",
      " Epoch 56 train loss: 3.55141516378265\n",
      "\n",
      " Epoch 56 validation acc: 0.20548780262470245\n",
      "\n",
      " Epoch 57 train loss: 3.5488936358366843\n",
      "\n",
      " Epoch 57 validation acc: 0.2050812989473343\n",
      "\n",
      " Epoch 58 train loss: 3.5468918189408822\n",
      "\n",
      " Epoch 58 validation acc: 0.20853658020496368\n",
      "\n",
      " Epoch 59 train loss: 3.545037332800209\n",
      "\n",
      " Epoch 59 validation acc: 0.21534551680088043\n",
      "\n",
      " Epoch 60 train loss: 3.5447170024627543\n",
      "\n",
      " Epoch 60 validation acc: 0.20630080997943878\n",
      "\n",
      " Epoch 61 train loss: 3.537908921203688\n",
      "\n",
      " Epoch 61 validation acc: 0.21026422083377838\n",
      "\n",
      " Epoch 62 train loss: 3.53815002334182\n",
      "\n",
      " Epoch 62 validation acc: 0.21046747267246246\n",
      "\n",
      " Epoch 63 train loss: 3.534595650144095\n",
      "\n",
      " Epoch 63 validation acc: 0.20081301033496857\n",
      "\n",
      " Epoch 64 train loss: 3.535527482878915\n",
      "\n",
      " Epoch 64 validation acc: 0.20579268038272858\n",
      "\n",
      " Epoch 65 train loss: 3.5343175887362235\n",
      "\n",
      " Epoch 65 validation acc: 0.2055894285440445\n",
      "\n",
      " Epoch 66 train loss: 3.530807354832115\n",
      "\n",
      " Epoch 66 validation acc: 0.20376016199588776\n",
      "\n",
      " Epoch 67 train loss: 3.5315734899955054\n",
      "\n",
      " Epoch 67 validation acc: 0.21473576128482819\n",
      "3.558387041091919\n",
      "\n",
      " Epoch 68 train loss: 3.52811847118479\n",
      "\n",
      " Epoch 68 validation acc: 0.20477642118930817\n",
      "\n",
      " Epoch 69 train loss: 3.5246625669581\n",
      "\n",
      " Epoch 69 validation acc: 0.20619918406009674\n",
      "\n",
      " Epoch 70 train loss: 3.5244912883639823\n",
      "\n",
      " Epoch 70 validation acc: 0.21138210594654083\n",
      "\n",
      " Epoch 71 train loss: 3.5204454269008254\n",
      "\n",
      " Epoch 71 validation acc: 0.21219511330127716\n",
      "\n",
      " Epoch 72 train loss: 3.5191940291805492\n",
      "\n",
      " Epoch 72 validation acc: 0.2014227658510208\n",
      "\n",
      " Epoch 73 train loss: 3.519254900411886\n",
      "\n",
      " Epoch 73 validation acc: 0.20182926952838898\n",
      "\n",
      " Epoch 74 train loss: 3.5191098459578503\n",
      "\n",
      " Epoch 74 validation acc: 0.2107723504304886\n",
      "\n",
      " Epoch 75 train loss: 3.5147601700341915\n",
      "\n",
      " Epoch 75 validation acc: 0.21209348738193512\n",
      "\n",
      " Epoch 76 train loss: 3.517984852993626\n",
      "\n",
      " Epoch 76 validation acc: 0.20233739912509918\n",
      "\n",
      " Epoch 77 train loss: 3.5128151767122175\n",
      "\n",
      " Epoch 77 validation acc: 0.2011178880929947\n",
      "\n",
      " Epoch 78 train loss: 3.5122847038817286\n",
      "\n",
      " Epoch 78 validation acc: 0.19563007354736328\n",
      "\n",
      " Epoch 79 train loss: 3.5127245788953387\n",
      "\n",
      " Epoch 79 validation acc: 0.2031504064798355\n",
      "\n",
      " Epoch 80 train loss: 3.513289682519772\n",
      "\n",
      " Epoch 80 validation acc: 0.21432925760746002\n",
      "\n",
      " Epoch 81 train loss: 3.512949772022515\n",
      "\n",
      " Epoch 81 validation acc: 0.2033536583185196\n",
      "\n",
      " Epoch 82 train loss: 3.509767975076045\n",
      "\n",
      " Epoch 82 validation acc: 0.2122967392206192\n",
      "\n",
      " Epoch 83 train loss: 3.5087994069992496\n",
      "\n",
      " Epoch 83 validation acc: 0.1914634108543396\n",
      "\n",
      " Epoch 84 train loss: 3.5069674929248524\n",
      "\n",
      " Epoch 84 validation acc: 0.2128048688173294\n",
      "\n",
      " Epoch 85 train loss: 3.502045975303308\n",
      "\n",
      " Epoch 85 validation acc: 0.21697154641151428\n",
      "3.536083459854126\n",
      "\n",
      " Epoch 86 train loss: 3.504162038209793\n",
      "\n",
      " Epoch 86 validation acc: 0.20853658020496368\n",
      "\n",
      " Epoch 87 train loss: 3.503794314439005\n",
      "\n",
      " Epoch 87 validation acc: 0.20741869509220123\n",
      "\n",
      " Epoch 88 train loss: 3.5064004005623577\n",
      "\n",
      " Epoch 88 validation acc: 0.21544714272022247\n",
      "\n",
      " Epoch 89 train loss: 3.502378087799771\n",
      "\n",
      " Epoch 89 validation acc: 0.20924796164035797\n",
      "\n",
      " Epoch 90 train loss: 3.5009629505745496\n",
      "\n",
      " Epoch 90 validation acc: 0.2179878056049347\n",
      "\n",
      " Epoch 91 train loss: 3.502497507419807\n",
      "\n",
      " Epoch 91 validation acc: 0.2011178880929947\n",
      "\n",
      " Epoch 92 train loss: 3.499310696476617\n",
      "\n",
      " Epoch 92 validation acc: 0.21768292784690857\n",
      "\n",
      " Epoch 93 train loss: 3.496626588290884\n",
      "\n",
      " Epoch 93 validation acc: 0.20589430630207062\n",
      "\n",
      " Epoch 94 train loss: 3.4987879371689687\n",
      "\n",
      " Epoch 94 validation acc: 0.21991869807243347\n",
      "3.523847818374634\n",
      "\n",
      " Epoch 95 train loss: 3.501020673122782\n",
      "\n",
      " Epoch 95 validation acc: 0.20701219141483307\n",
      "\n",
      " Epoch 96 train loss: 3.498684612415271\n",
      "\n",
      " Epoch 96 validation acc: 0.19908535480499268\n",
      "\n",
      " Epoch 97 train loss: 3.498410245349319\n",
      "\n",
      " Epoch 97 validation acc: 0.20243902504444122\n",
      "\n",
      " Epoch 98 train loss: 3.4979954087153424\n",
      "\n",
      " Epoch 98 validation acc: 0.20741869509220123\n",
      "\n",
      " Epoch 99 train loss: 3.4990090626894856\n",
      "\n",
      " Epoch 99 validation acc: 0.2140243798494339\n",
      "\n",
      " Epoch 100 train loss: 3.4949812564318394\n",
      "\n",
      " Epoch 100 validation acc: 0.20691056549549103\n",
      "\n",
      " Epoch 101 train loss: 3.496476610844777\n",
      "\n",
      " Epoch 101 validation acc: 0.21290649473667145\n",
      "\n",
      " Epoch 102 train loss: 3.496132128476048\n",
      "\n",
      " Epoch 102 validation acc: 0.21046747267246246\n",
      "\n",
      " Epoch 103 train loss: 3.495587341090416\n",
      "\n",
      " Epoch 103 validation acc: 0.20741869509220123\n",
      "\n",
      " Epoch 104 train loss: 3.495083957808558\n",
      "\n",
      " Epoch 104 validation acc: 0.21321137249469757\n",
      "\n",
      " Epoch 105 train loss: 3.4882545006941443\n",
      "\n",
      " Epoch 105 validation acc: 0.21514226496219635\n",
      "\n",
      " Epoch 106 train loss: 3.4953227885794673\n",
      "\n",
      " Epoch 106 validation acc: 0.2088414579629898\n",
      "\n",
      " Epoch 107 train loss: 3.4928524260686435\n",
      "\n",
      " Epoch 107 validation acc: 0.21209348738193512\n",
      "\n",
      " Epoch 108 train loss: 3.4873521852438896\n",
      "\n",
      " Epoch 108 validation acc: 0.211788609623909\n",
      "\n",
      " Epoch 109 train loss: 3.4905725767465996\n",
      "\n",
      " Epoch 109 validation acc: 0.21371950209140778\n",
      "\n",
      " Epoch 110 train loss: 3.4873664382227823\n",
      "\n",
      " Epoch 110 validation acc: 0.1983739733695984\n",
      "\n",
      " Epoch 111 train loss: 3.490401578683777\n",
      "\n",
      " Epoch 111 validation acc: 0.21392275393009186\n",
      "\n",
      " Epoch 112 train loss: 3.484063457933761\n",
      "\n",
      " Epoch 112 validation acc: 0.21534551680088043\n",
      "\n",
      " Epoch 113 train loss: 3.490031435180025\n",
      "\n",
      " Epoch 113 validation acc: 0.21819105744361877\n",
      "\n",
      " Epoch 114 train loss: 3.4907118589225026\n",
      "\n",
      " Epoch 114 validation acc: 0.21361787617206573\n",
      "\n",
      " Epoch 115 train loss: 3.4827869781088863\n",
      "\n",
      " Epoch 115 validation acc: 0.21666666865348816\n",
      "\n",
      " Epoch 116 train loss: 3.486324711111677\n",
      "\n",
      " Epoch 116 validation acc: 0.20985771715641022\n",
      "\n",
      " Epoch 117 train loss: 3.486774146294621\n",
      "\n",
      " Epoch 117 validation acc: 0.2128048688173294\n",
      "\n",
      " Epoch 118 train loss: 3.4877357800697997\n",
      "\n",
      " Epoch 118 validation acc: 0.21514226496219635\n",
      "\n",
      " Epoch 119 train loss: 3.4858809471985057\n",
      "\n",
      " Epoch 119 validation acc: 0.21016259491443634\n",
      "\n",
      " Epoch 120 train loss: 3.488205485843536\n",
      "\n",
      " Epoch 120 validation acc: 0.21656504273414612\n",
      "\n",
      " Epoch 121 train loss: 3.48768857979553\n",
      "\n",
      " Epoch 121 validation acc: 0.21808943152427673\n",
      "3.51369047164917\n",
      "\n",
      " Epoch 122 train loss: 3.4858665078980384\n",
      "\n",
      " Epoch 122 validation acc: 0.21646341681480408\n",
      "\n",
      " Epoch 123 train loss: 3.4876710598954785\n",
      "\n",
      " Epoch 123 validation acc: 0.2195121943950653\n",
      "\n",
      " Epoch 124 train loss: 3.484674182314233\n",
      "\n",
      " Epoch 124 validation acc: 0.21554876863956451\n",
      "\n",
      " Epoch 125 train loss: 3.4865207479814764\n",
      "\n",
      " Epoch 125 validation acc: 0.21839430928230286\n",
      "\n",
      " Epoch 126 train loss: 3.486282910083897\n",
      "\n",
      " Epoch 126 validation acc: 0.21219511330127716\n",
      "\n",
      " Epoch 127 train loss: 3.480077967691134\n",
      "\n",
      " Epoch 127 validation acc: 0.206808939576149\n",
      "\n",
      " Epoch 128 train loss: 3.4807805306402155\n",
      "\n",
      " Epoch 128 validation acc: 0.21443088352680206\n",
      "\n",
      " Epoch 129 train loss: 3.4785007364454263\n",
      "\n",
      " Epoch 129 validation acc: 0.22042682766914368\n",
      "\n",
      " Epoch 130 train loss: 3.4746569052219622\n",
      "\n",
      " Epoch 130 validation acc: 0.21544714272022247\n",
      "\n",
      " Epoch 131 train loss: 3.476183876805572\n",
      "\n",
      " Epoch 131 validation acc: 0.2112804800271988\n",
      "\n",
      " Epoch 132 train loss: 3.4798033934026464\n",
      "\n",
      " Epoch 132 validation acc: 0.2219512164592743\n",
      "\n",
      " Epoch 133 train loss: 3.473953600560723\n",
      "\n",
      " Epoch 133 validation acc: 0.2073170691728592\n",
      "\n",
      " Epoch 134 train loss: 3.476750353522112\n",
      "\n",
      " Epoch 134 validation acc: 0.19695121049880981\n",
      "\n",
      " Epoch 135 train loss: 3.4750046002392816\n",
      "\n",
      " Epoch 135 validation acc: 0.21158535778522491\n",
      "\n",
      " Epoch 136 train loss: 3.470098195915912\n",
      "\n",
      " Epoch 136 validation acc: 0.21615853905677795\n",
      "\n",
      " Epoch 137 train loss: 3.4753922187332145\n",
      "\n",
      " Epoch 137 validation acc: 0.20985771715641022\n",
      "\n",
      " Epoch 138 train loss: 3.4744536481968877\n",
      "\n",
      " Epoch 138 validation acc: 0.21483738720417023\n",
      "\n",
      " Epoch 139 train loss: 3.4734284641184443\n",
      "\n",
      " Epoch 139 validation acc: 0.20101626217365265\n",
      "\n",
      " Epoch 140 train loss: 3.474682472069566\n",
      "\n",
      " Epoch 140 validation acc: 0.21707317233085632\n",
      "\n",
      " Epoch 141 train loss: 3.4684705495329307\n",
      "\n",
      " Epoch 141 validation acc: 0.21839430928230286\n",
      "\n",
      " Epoch 142 train loss: 3.474456418428861\n",
      "\n",
      " Epoch 142 validation acc: 0.2174796760082245\n",
      "\n",
      " Epoch 143 train loss: 3.4704406236580496\n",
      "\n",
      " Epoch 143 validation acc: 0.21941056847572327\n",
      "\n",
      " Epoch 144 train loss: 3.4705779541581894\n",
      "\n",
      " Epoch 144 validation acc: 0.21554876863956451\n",
      "\n",
      " Epoch 145 train loss: 3.466803892944309\n",
      "\n",
      " Epoch 145 validation acc: 0.21514226496219635\n",
      "\n",
      " Epoch 146 train loss: 3.4661256158237292\n",
      "\n",
      " Epoch 146 validation acc: 0.20853658020496368\n",
      "\n",
      " Epoch 147 train loss: 3.4687243908454333\n",
      "\n",
      " Epoch 147 validation acc: 0.2214430868625641\n",
      "\n",
      " Epoch 148 train loss: 3.466775496464046\n",
      "\n",
      " Epoch 148 validation acc: 0.21819105744361877\n",
      "\n",
      " Epoch 149 train loss: 3.4685726242693233\n",
      "\n",
      " Epoch 149 validation acc: 0.22621950507164001\n",
      "3.5016472339630127\n",
      "\n",
      " Epoch 150 train loss: 3.471615858141716\n",
      "\n",
      " Epoch 150 validation acc: 0.21016259491443634\n",
      "\n",
      " Epoch 151 train loss: 3.469531290613131\n",
      "\n",
      " Epoch 151 validation acc: 0.2197154462337494\n",
      "\n",
      " Epoch 152 train loss: 3.46818725764023\n",
      "\n",
      " Epoch 152 validation acc: 0.22083333134651184\n",
      "\n",
      " Epoch 153 train loss: 3.464530115895227\n",
      "\n",
      " Epoch 153 validation acc: 0.21087397634983063\n",
      "\n",
      " Epoch 154 train loss: 3.466182033732444\n",
      "\n",
      " Epoch 154 validation acc: 0.2093495875597\n",
      "\n",
      " Epoch 155 train loss: 3.4668768909091336\n",
      "\n",
      " Epoch 155 validation acc: 0.19481706619262695\n",
      "\n",
      " Epoch 156 train loss: 3.467291813050572\n",
      "\n",
      " Epoch 156 validation acc: 0.21189023554325104\n",
      "\n",
      " Epoch 157 train loss: 3.4690401486509765\n",
      "\n",
      " Epoch 157 validation acc: 0.2112804800271988\n",
      "\n",
      " Epoch 158 train loss: 3.4658942905567125\n",
      "\n",
      " Epoch 158 validation acc: 0.21199186146259308\n",
      "\n",
      " Epoch 159 train loss: 3.464543416948025\n",
      "\n",
      " Epoch 159 validation acc: 0.21341462433338165\n",
      "\n",
      " Epoch 160 train loss: 3.467569744041111\n",
      "\n",
      " Epoch 160 validation acc: 0.21036584675312042\n",
      "\n",
      " Epoch 161 train loss: 3.4587759688601\n",
      "\n",
      " Epoch 161 validation acc: 0.21148373186588287\n",
      "\n",
      " Epoch 162 train loss: 3.4604530654202965\n",
      "\n",
      " Epoch 162 validation acc: 0.21697154641151428\n",
      "\n",
      " Epoch 163 train loss: 3.4610195530146597\n",
      "\n",
      " Epoch 163 validation acc: 0.20640243589878082\n",
      "\n",
      " Epoch 164 train loss: 3.4594047740478167\n",
      "\n",
      " Epoch 164 validation acc: 0.22560974955558777\n",
      "3.492832660675049\n",
      "\n",
      " Epoch 165 train loss: 3.461684260244806\n",
      "\n",
      " Epoch 165 validation acc: 0.22225609421730042\n",
      "\n",
      " Epoch 166 train loss: 3.4591150356461795\n",
      "\n",
      " Epoch 166 validation acc: 0.2053861767053604\n",
      "\n",
      " Epoch 167 train loss: 3.4601266137819753\n",
      "\n",
      " Epoch 167 validation acc: 0.2207317054271698\n",
      "\n",
      " Epoch 168 train loss: 3.46150235498847\n",
      "\n",
      " Epoch 168 validation acc: 0.22093495726585388\n",
      "\n",
      " Epoch 169 train loss: 3.4585925288788557\n",
      "\n",
      " Epoch 169 validation acc: 0.2130081206560135\n",
      "\n",
      " Epoch 170 train loss: 3.455606082761173\n",
      "\n",
      " Epoch 170 validation acc: 0.22012194991111755\n",
      "\n",
      " Epoch 171 train loss: 3.4548368341704814\n",
      "\n",
      " Epoch 171 validation acc: 0.2246951162815094\n",
      "3.490365505218506\n",
      "\n",
      " Epoch 172 train loss: 3.455693166341808\n",
      "\n",
      " Epoch 172 validation acc: 0.20752032101154327\n",
      "\n",
      " Epoch 173 train loss: 3.4557640458116783\n",
      "\n",
      " Epoch 173 validation acc: 0.21097560226917267\n",
      "\n",
      " Epoch 174 train loss: 3.4579207354849086\n",
      "\n",
      " Epoch 174 validation acc: 0.2184959352016449\n",
      "\n",
      " Epoch 175 train loss: 3.4590305881117964\n",
      "\n",
      " Epoch 175 validation acc: 0.21697154641151428\n",
      "\n",
      " Epoch 176 train loss: 3.4551844111245678\n",
      "\n",
      " Epoch 176 validation acc: 0.21249999105930328\n",
      "\n",
      " Epoch 177 train loss: 3.457504418767662\n",
      "\n",
      " Epoch 177 validation acc: 0.21412600576877594\n",
      "\n",
      " Epoch 178 train loss: 3.455574849111474\n",
      "\n",
      " Epoch 178 validation acc: 0.22510161995887756\n",
      "\n",
      " Epoch 179 train loss: 3.4568941154560786\n",
      "\n",
      " Epoch 179 validation acc: 0.21737805008888245\n",
      "\n",
      " Epoch 180 train loss: 3.4561317161257343\n",
      "\n",
      " Epoch 180 validation acc: 0.22042682766914368\n",
      "\n",
      " Epoch 181 train loss: 3.4565345615133976\n",
      "\n",
      " Epoch 181 validation acc: 0.2200203239917755\n",
      "\n",
      " Epoch 182 train loss: 3.452134466567528\n",
      "\n",
      " Epoch 182 validation acc: 0.21443088352680206\n",
      "\n",
      " Epoch 183 train loss: 3.453839258590544\n",
      "\n",
      " Epoch 183 validation acc: 0.2090447098016739\n",
      "\n",
      " Epoch 184 train loss: 3.4525945091822527\n",
      "\n",
      " Epoch 184 validation acc: 0.21412600576877594\n",
      "\n",
      " Epoch 185 train loss: 3.4519092397579487\n",
      "\n",
      " Epoch 185 validation acc: 0.2276422679424286\n",
      "3.4873123168945312\n",
      "\n",
      " Epoch 186 train loss: 3.4524005024250934\n",
      "\n",
      " Epoch 186 validation acc: 0.22042682766914368\n",
      "\n",
      " Epoch 187 train loss: 3.451972918924571\n",
      "\n",
      " Epoch 187 validation acc: 0.2112804800271988\n",
      "\n",
      " Epoch 188 train loss: 3.4498959409310643\n",
      "\n",
      " Epoch 188 validation acc: 0.21890243887901306\n",
      "\n",
      " Epoch 189 train loss: 3.451444165955659\n",
      "\n",
      " Epoch 189 validation acc: 0.22184959053993225\n",
      "\n",
      " Epoch 190 train loss: 3.457678806321404\n",
      "\n",
      " Epoch 190 validation acc: 0.2184959352016449\n",
      "\n",
      " Epoch 191 train loss: 3.450346217863292\n",
      "\n",
      " Epoch 191 validation acc: 0.21392275393009186\n",
      "\n",
      " Epoch 192 train loss: 3.457798416808391\n",
      "\n",
      " Epoch 192 validation acc: 0.21493901312351227\n",
      "\n",
      " Epoch 193 train loss: 3.4534923030709685\n",
      "\n",
      " Epoch 193 validation acc: 0.21595527231693268\n",
      "\n",
      " Epoch 194 train loss: 3.4480832956387744\n",
      "\n",
      " Epoch 194 validation acc: 0.21890243887901306\n",
      "\n",
      " Epoch 195 train loss: 3.4546994945795895\n",
      "\n",
      " Epoch 195 validation acc: 0.20924796164035797\n",
      "\n",
      " Epoch 196 train loss: 3.4554356773454784\n",
      "\n",
      " Epoch 196 validation acc: 0.2217479646205902\n",
      "\n",
      " Epoch 197 train loss: 3.4533843638280404\n",
      "\n",
      " Epoch 197 validation acc: 0.21239836513996124\n",
      "\n",
      " Epoch 198 train loss: 3.447599951055824\n",
      "\n",
      " Epoch 198 validation acc: 0.2066056877374649\n",
      "\n",
      " Epoch 199 train loss: 3.447145051204053\n",
      "\n",
      " Epoch 199 validation acc: 0.22012194991111755\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(f'number of param: {num_params}')\n",
    "print(f'number of iters: {len(train_dataloader)}')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=wd, betas=(0.9, 0.98))\n",
    "\n",
    "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, end_factor=1.0, total_iters=warmup_steps)\n",
    "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, total_train_steps-warmup_steps, eta_min=max_lr*0.01)\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, [scheduler1, scheduler2], [warmup_steps])\n",
    "\n",
    "# %%\n",
    "import math\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "test_name = f\"{config.dataset}_vit_{config.num_epoches}_direction_{config.ssm_direction}\"\n",
    "# test_name = 'cnn_4_stage'\n",
    "writer = SummaryWriter(path+'/runs/'+test_name, max_queue=120)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "train_step = 0\n",
    "\n",
    "\n",
    "best_loss = float('inf')\n",
    "for epoch in range(epoches):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    #indices = torch.randperm(train_x.shape[0])\n",
    "    for img, label in train_dataloader:\n",
    "        #img, label = train_x[indices[i:i+batch_size]], train_y[indices[i:i+batch_size]]\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        #img, label = cutmix_or_mixup(img, label)\n",
    "        batch_loss = 0\n",
    "        model.train()\n",
    "        # for mini_data in data.chunk(num_mini_batches, 0):\n",
    "        with torch.autocast(device_type=\"cuda\"):\n",
    "            output = model(img)\n",
    "            final_output = torch.reshape(output, (-1, output.shape[-1]))\n",
    "            loss = F.cross_entropy(final_output, label) \n",
    "\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1e2)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    " \n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        writer.add_scalar('Loss/train', batch_loss, train_step)\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "        train_step += 1\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    print(f'\\n Epoch {epoch} train loss: {avg_loss}')\n",
    "    writer.add_scalar('Loss/train_average', avg_loss, epoch)\n",
    "\n",
    "\n",
    "    \n",
    "    losses.clear()\n",
    "    accs = []\n",
    "    model.eval()\n",
    "    for img, label in val_dataloader:\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        with torch.inference_mode(), torch.autocast(device_type=\"cuda\"):\n",
    "            \n",
    "            output = model(img)\n",
    "            final_target = torch.reshape(label, (-1,))\n",
    "            loss = F.cross_entropy(output, final_target, reduction='none')\n",
    "            \n",
    "            pred_labels = output.argmax(1)\n",
    "            acc = (pred_labels==label).float().mean()\n",
    "            accs.append(acc)\n",
    "\n",
    "\n",
    "        losses.append(loss.cpu().numpy())\n",
    "    \n",
    "    avg_loss = np.mean(np.concatenate(losses, 0)).item()\n",
    "    avg_acc= sum(accs) / len(accs)\n",
    "    print(f'\\n Epoch {epoch} validation acc: {avg_acc}')\n",
    "\n",
    "    writer.add_scalar('Loss/valid', avg_loss, i)\n",
    "\n",
    "    writer.add_scalar('Acc/valid', avg_acc, i)\n",
    "\n",
    "\n",
    "    losses.clear()\n",
    "\n",
    "    if avg_loss <= best_loss:\n",
    "        print(avg_loss)\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), path+'/runs/'+test_name+'/best_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
